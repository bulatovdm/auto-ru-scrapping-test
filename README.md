# auto-ru-scrapping-test
 *Тестирование парсинга auto.ru*
 
Добрый день! В проекте представил часть приложения, которая отвечает за сбор данных с листинга auto.ru. Вначале расскажу суть проблемы, далее – шаги по настройке окружения, после – краткое описание работы. В конце будет ссылка на небольшое видео с демонстрацией.

## Суть проблемы

Приложение собирало данные с auto.ru с помощью прокси. В конце августа auto.ru стал подменять данные при использовании такого метода сбора. Для получения кода используется библиотека *requests*. В результате тестов пришел к следующим выводам. По всей видимости, когда пользователь открывает сайт с обычного браузера, случайным образом генерируются cookie с идентификатором пользователя. Эта запись проверяется сервером. Если она есть, но не совпадает со «слепком браузера» (это некий идентификатор браузера, его параметры, сборка), то тут срабатывает системы подмены данных.

Почему так считаю: дело не в прокси, вернее, не в них одних. Когда не используем прокси, если IP «чистый», то защита тоже не срабатывает. Например, моя домашняя машина корректно собирает данные, но при использовании с любых прокси отдает искаженные значения. То есть у auto.ru эта система работает в связке с прокси.

Сейчас переписываю проект с использованием «безголового» браузера с помощью *selenium* – там проблема не воспроизводится (но есть другая проблемы – скорость и ресурсы, которые «кушает» web-драйвер).

## Настройка окружения

```console
# Создаем виртуальное окружение
python3 -m venv venv

# Активируем рабочую среду
source venv/bin/activate

# Обновляем pip
pip install --upgrade pip

# Устанавливаем библиотеки
pip install pylint
pip install autopep8
pip install bs4
pip install requests
```
Если используем VS Code – в файле с настройками VS Code (.code-workspace) указываем:

```json
{
	"folders": [
		{
			"path": "."
		}
  ],
  "settings": {
    "python.languageServer": "Jedi",
    "python.formatting.autopep8Path": "autopep8",
    "python.autoComplete.extraPaths": [
      "venv/lib/python3.8/site-packages",
      "modules",
      "configs",
      "utils"
    ],
    "editor.formatOnSave": true,
    "[python]": {
      "editor.insertSpaces": true,
      "editor.tabSize": 4
    },
  },
}
```

В папке *extras* есть файл *module-pathes.pth*. Его нужно закинуть в директорию *venv/lib/python3.8/site-packages/* (чтобы модули из других директорий подтягивались)

Ну и перед запуском программы
```console
source venv/bin/activate
```

## Описание работы
Логика части приложения, которая вынесена в этом проекте – в файле *app/offers_scrapper.py*.

1. Подготавливаем массив опций, включающий данные о прокси (в нашем примере – один прокси, для демонстрации – достаточно).
2. Запускаем все это через *Pool*.
3. Забираем данные со страницы через *requests*. 
4. Находим предложения на странице, получаем данные: ссылка, название, цена, пробег.
5. Выводим.

## Ссылка на видео с демонстрацией искажения данных:
https://youtu.be/69iJW4tF6Fw
